# Default configuration for Poisson-Gaussian Diffusion

# Model configuration
model:
  architecture: "EDM"
  img_channels: 1
  img_resolution: 128
  model_channels: 128
  channel_mult: [1, 2, 4, 4]  # Better feature hierarchy
  condition_dim: 6
  dropout: 0.1  # Add regularization

# Training configuration
training:
  batch_size: 16  # Increased for better GPU utilization
  learning_rate: 2e-4  # Slightly higher for faster convergence
  num_epochs: 100
  gradient_clip: 1.0
  mixed_precision: true
  # Learning rate scheduling
  scheduler: "cosine"
  warmup_epochs: 5
  min_lr: 1e-6
  # Gradient accumulation for effective larger batch sizes
  accumulate_grad_batches: 2  # Effective batch size = 32
  # Optimizer settings
  optimizer: "adamw"
  weight_decay: 1e-2
  beta1: 0.9
  beta2: 0.999

# Sampling configuration
sampling:
  steps: 18
  sigma_min: 0.002
  sigma_max: 80.0
  rho: 7.0
  guidance_weight: 1.0

# Data configuration
data:
  target_size: 128
  patch_size: null  # Use full images
  augment: true
  num_workers: 8  # Increased for better I/O parallelism
  pin_memory: true  # Faster GPU transfers
  persistent_workers: true  # Avoid worker respawning
  prefetch_factor: 2  # Prefetch batches

# Domain configurations
domains:
  photography:
    pixel_size: 4.29  # μm
    pixel_unit: "um"
    extensions: [".arw", ".dng", ".nef", ".cr2"]
    black_level: 512
    white_level: 16383

  microscopy:
    pixel_size: 0.65  # μm at 20x
    pixel_unit: "um"
    extensions: [".tif", ".tiff"]
    black_level: 100
    white_level: 65535

  astronomy:
    pixel_size: 0.04  # arcsec
    pixel_unit: "arcsec"
    extensions: [".fits", ".fit"]
    black_level: 0
    white_level: 65535

# Guidance configuration
guidance:
  mode: "wls"  # or "exact"
  gamma_schedule: "sigma2"  # or "linear", "const"
  kappa: 0.5
  gradient_clip: 10.0

# Evaluation configuration
evaluation:
  metrics: ["psnr", "ssim", "lpips", "chi2"]
  save_images: true
  compute_physics_metrics: true

# Logging and output
logging:
  level: "INFO"
  log_file: "logs/training.log"

output:
  checkpoint_dir: "checkpoints"
  results_dir: "results"
  save_frequency: 10  # epochs
