"""
Dataset classes for loading preprocessed .pt files.

This module provides dataset classes specifically for loading the preprocessed
.pt files generated by the preprocessing pipeline.
"""

import json
import logging
import random
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

import torch
from torch.utils.data import Dataset

from core.logging_config import get_logger

logger = get_logger(__name__)


class PreprocessedPriorDataset(Dataset):
    """
    Dataset for loading preprocessed prior clean tiles (.pt files).

    This dataset loads the 128x128 clean tiles from prior_clean directory
    which are perfect for diffusion model training.
    """

    def __init__(
        self,
        data_root: Union[str, Path],
        domain: str = "photography",
        split: str = "train",
        max_files: Optional[int] = None,
        seed: int = 42,
    ):
        """
        Initialize preprocessed prior dataset.

        Args:
            data_root: Root directory containing preprocessed data
            domain: Domain name (photography, microscopy, astronomy)
            split: Data split (train, val, test)
            max_files: Maximum number of files to load (for testing)
            seed: Random seed for file selection
        """
        self.data_root = Path(data_root)
        self.domain = domain
        self.split = split
        self.max_files = max_files

        # Find all .pt files in the prior_clean directory
        prior_dir = self.data_root / "prior_clean" / domain / split
        if not prior_dir.exists():
            raise FileNotFoundError(f"Prior clean directory not found: {prior_dir}")

        all_files = list(prior_dir.glob("*.pt"))

        if not all_files:
            raise ValueError(f"No .pt files found in {prior_dir}")

        # Filter out corrupted files
        self.files = []
        for file_path in all_files:
            try:
                # Quick test load to check if file is valid
                torch.load(file_path, map_location="cpu", weights_only=False)
                self.files.append(file_path)
            except Exception as e:
                logger.warning(f"Skipping corrupted file {file_path}: {e}")

        if not self.files:
            raise ValueError(f"No valid .pt files found in {prior_dir}")

        # Limit files if requested
        if max_files is not None and len(self.files) > max_files:
            random.seed(seed)
            self.files = random.sample(self.files, max_files)

        logger.info(
            f"Loaded {len(self.files)} valid preprocessed {domain} {split} files (filtered from {len(all_files)} total)"
        )

    def __len__(self) -> int:
        return len(self.files)

    def __getitem__(self, idx: int) -> Dict[str, Any]:
        """
        Load a preprocessed tile.

        Returns:
            Dictionary containing:
            - clean: Clean image tensor [C, H, W]
            - noisy: Noisy version (we'll add noise during training)
            - domain: Domain tensor
            - metadata: Metadata dictionary
        """
        file_path = self.files[idx]

        try:
            # Use weights_only=False for older PyTorch compatibility
            data = torch.load(file_path, map_location="cpu", weights_only=False)

            # Extract clean image
            clean = data["clean_norm"]  # [4, 128, 128] for photography

            # Convert 4-channel RGGB to 1-channel grayscale for model compatibility
            # Simple approach: average the 4 channels
            if clean.shape[0] == 4:
                clean = clean.mean(dim=0, keepdim=True)  # [1, 128, 128]

            # For diffusion training, we need to add noise to create noisy version
            # For now, use clean as both clean and noisy (noise will be added in trainer)
            noisy = clean.clone()

            # Add some synthetic noise for training
            noise_std = 0.1
            noisy = noisy + torch.randn_like(clean) * noise_std

            return {
                "clean": clean.float(),
                "noisy": noisy.float(),
                "electrons": clean.float(),  # Target for loss function
                "domain": torch.tensor([data.get("domain_id", 0)]),
                "metadata": data.get("metadata", {}),
            }

        except Exception as e:
            logger.warning(f"Error loading {file_path}: {e}")
            # Return a dummy sample instead of recursion to prevent infinite loops
            return {
                "clean": torch.zeros(1, 128, 128, dtype=torch.float32),
                "noisy": torch.zeros(1, 128, 128, dtype=torch.float32),
                "electrons": torch.zeros(1, 128, 128, dtype=torch.float32),
                "domain": torch.tensor([0]),
                "metadata": {"corrupted": True, "original_idx": idx},
            }


class PreprocessedMultiDomainDataset:
    """
    Multi-domain dataset for preprocessed data.

    This creates train/val datasets from preprocessed .pt files
    and provides the interface expected by MultiDomainTrainer.
    """

    def __init__(
        self,
        domain_configs: Dict[str, Dict[str, Any]],
        split: str = "train",
        balance_domains: bool = False,
        **kwargs,
    ):
        """
        Initialize multi-domain preprocessed dataset.

        Args:
            domain_configs: Configuration for each domain
            split: Data split to load
            balance_domains: Whether to balance domain sampling
        """
        self.domain_configs = domain_configs
        self.split = split
        self.balance_domains = balance_domains

        # Create individual domain datasets
        self.domain_datasets = {}

        for domain, config in domain_configs.items():
            try:
                dataset = PreprocessedPriorDataset(
                    data_root=config["data_root"],
                    domain=domain,
                    split=split,
                    max_files=config.get("max_files"),
                    seed=config.get("seed", 42),
                )
                self.domain_datasets[domain] = dataset
                logger.info(f"Created {domain} dataset with {len(dataset)} samples")

            except Exception as e:
                logger.error(f"Failed to create {domain} dataset: {e}")
                continue

        if not self.domain_datasets:
            raise ValueError("No valid domain datasets could be created")

        # Create combined dataset
        all_datasets = list(self.domain_datasets.values())
        if len(all_datasets) == 1:
            self.combined_dataset = all_datasets[0]
        else:
            from torch.utils.data import ConcatDataset

            self.combined_dataset = ConcatDataset(all_datasets)

        logger.info(
            f"Created multi-domain dataset with {len(self.combined_dataset)} total samples"
        )

    def __len__(self) -> int:
        return len(self.combined_dataset)

    def __getitem__(self, idx: int) -> Dict[str, Any]:
        return self.combined_dataset[idx]


def create_preprocessed_datasets(
    data_root: Union[str, Path],
    domain: str = "photography",
    max_files: Optional[int] = None,
    seed: int = 42,
    val_split: float = 0.2,
) -> Tuple[PreprocessedMultiDomainDataset, PreprocessedMultiDomainDataset]:
    """
    Create train and validation datasets from preprocessed data.

    Args:
        data_root: Root directory containing preprocessed data
        domain: Domain to load
        max_files: Maximum files per split
        seed: Random seed
        val_split: Fraction of training data to use for validation

    Returns:
        Tuple of (train_dataset, val_dataset)
    """
    # Load all training files and create manual split
    prior_dir = Path(data_root) / "prior_clean" / domain / "train"
    all_files = list(prior_dir.glob("*.pt"))

    if not all_files:
        raise ValueError(f"No training files found in {prior_dir}")

    # Limit files if requested
    if max_files is not None and len(all_files) > max_files:
        random.seed(seed)
        all_files = random.sample(all_files, max_files)

    # Split files
    random.seed(seed)
    random.shuffle(all_files)

    val_size = int(len(all_files) * val_split)
    val_files = all_files[:val_size]
    train_files = all_files[val_size:]

    logger.info(
        f"Split {len(all_files)} files: {len(train_files)} train, {len(val_files)} val"
    )

    # Create custom datasets with specific file lists
    class CustomPreprocessedDataset(PreprocessedPriorDataset):
        def __init__(self, files, domain, split):
            self.files = files
            self.domain = domain
            self.split = split

    train_ds = CustomPreprocessedDataset(train_files, domain, "train")
    val_ds = CustomPreprocessedDataset(val_files, domain, "val")

    # Wrap in multi-domain format
    class SimpleMultiDomainDataset:
        def __init__(self, dataset, domain):
            self.combined_dataset = dataset
            self.domain_datasets = {domain: dataset}

        def __len__(self):
            return len(self.combined_dataset)

        def __getitem__(self, idx):
            return self.combined_dataset[idx]

    train_dataset = SimpleMultiDomainDataset(train_ds, domain)
    val_dataset = SimpleMultiDomainDataset(val_ds, domain)

    return train_dataset, val_dataset
